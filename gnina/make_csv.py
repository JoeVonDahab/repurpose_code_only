#!/usr/bin/env python3
import glob
import pandas as pd
import re
import argparse
import os

def parse_sdf_scores(filename):
    """Parse scores from an SDF file generated by gnina"""
    scores = {}
    try:
        with open(filename, 'r') as f:
            content = f.read()
            
        # Look for score lines in SDF format
        # Example lines:
        # >  <minimizedAffinity>
        # -7.123
        # 
        # >  <CNNscore>
        # 0.456
        
        patterns = {
            'minimizedAffinity': r'> <(?:minimized)?[Aa]ffinity>\s*\n([-+]?\d*\.?\d+)',
            'Affinity': r'> <(?:minimized)?[Aa]ffinity>\s*\n([-+]?\d*\.?\d+)',
            'CNNscore': r'> <CNNscore>\s*\n([-+]?\d*\.?\d+)',
            'CNNaffinity': r'> <CNNaffinity>\s*\n([-+]?\d*\.?\d+)',
            'CNN_VS': r'> <CNN_VS>\s*\n([-+]?\d*\.?\d+)'
        }
        
        for score_name, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                scores[score_name] = float(match.group(1))
            else:
                scores[score_name] = None
                
    except Exception as e:
        raise Exception(f"Error parsing {filename}: {e}")
    
    return scores

def main():
    parser = argparse.ArgumentParser(description='Parse gnina SDF scores and create CSV')
    parser.add_argument('--input_dir', required=True, help='Directory containing scored SDF files')
    parser.add_argument('--csv_path', required=True, help='Output CSV file path')
    
    args = parser.parse_args()
    
    rows = []
    skipped = []
    
    # Look for scored SDF files in the input directory
    pattern = os.path.join(args.input_dir, "*_scored.sdf")
    
    for fn in glob.glob(pattern):
        base = os.path.basename(fn).replace("_scored.sdf", "")
        try:
            scores = parse_sdf_scores(fn)
            data = {"ligand": base}
            data.update(scores)
            rows.append(data)
        except Exception as e:
            skipped.append((base, str(e)))
            continue

    # Report skipped files
    if skipped:
        print(f"⚠️  Skipped {len(skipped)} files due to parse errors:")
        for name, err in skipped:
            print(f"  - {name}: {err}")

    # Build and write the CSV
    df = pd.DataFrame(rows)
    # Sort by Affinity (more negative = better binding)
    df = df.sort_values("Affinity", ascending=True).reset_index(drop=True)
    for index, row in df.iterrows():
        ligand_name = row['ligand']
        ligand_name = ligand_name.replace("_best_pose", "")
        df.at[index, 'ligand'] = ligand_name
    df = df.rename(columns={'ligand': 'drug'})
    df.to_csv(args.csv_path, index=False)
    print(f"✅  Wrote {len(df)} scored ligands to {args.csv_path}")

if __name__ == "__main__":
    main()
